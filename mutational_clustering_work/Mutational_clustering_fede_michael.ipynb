{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d76882f-629a-47ec-9fca-3e42eff41150",
   "metadata": {},
   "source": [
    "### List of Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91b45735-f5e8-4081-a9c8-60a0729c7ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vb/_j3bfqg90fs67sllgj229fz00000gn/T/ipykernel_15757/784890291.py:8: DeprecationWarning: The current Dask DataFrame implementation is deprecated. \n",
      "In a future release, Dask DataFrame will use a new implementation that\n",
      "contains several improvements including a logical query planning.\n",
      "The user-facing DataFrame API will remain unchanged.\n",
      "\n",
      "The new implementation is already available and can be enabled by\n",
      "installing the dask-expr library:\n",
      "\n",
      "    $ pip install dask-expr\n",
      "\n",
      "and turning the query planning option on:\n",
      "\n",
      "    >>> import dask\n",
      "    >>> dask.config.set({'dataframe.query-planning': True})\n",
      "    >>> import dask.dataframe as dd\n",
      "\n",
      "API documentation for the new implementation is available at\n",
      "https://docs.dask.org/en/stable/dask-expr-api.html\n",
      "\n",
      "Any feedback can be reported on the Dask issue tracker\n",
      "https://github.com/dask/dask/issues \n",
      "\n",
      "To disable this warning in the future, set dask config:\n",
      "\n",
      "    # via Python\n",
      "    >>> dask.config.set({'dataframe.query-planning-warning': False})\n",
      "\n",
      "    # via CLI\n",
      "    dask config set dataframe.query-planning-warning False\n",
      "\n",
      "\n",
      "  import dask.dataframe as dd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "from Bio.PDB import Selection, NeighborSearch\n",
    "from collections import defaultdict\n",
    "from Bio.PDB import PDBParser\n",
    "import dask.dataframe as dd\n",
    "#import pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b264d59-9364-4f0f-85b0-514f880e420f",
   "metadata": {},
   "source": [
    "# Paths definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbcfbb06-2ad3-453a-b971-43b391976fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User dependent paths (must be passed as arguments)\n",
    "work_dir= \"/Users/fede/Desktop/Lab/Git/project_orellana_lab/mutational_clustering_work\"\n",
    "cosmic_tar=\"/Users/fede/Heavyfiles/Cosmic_GenomeScreensMutant_Tsv_v99_GRCh37/Cosmic_GenomeScreensMutant_v99_GRCh37.tsv\"\n",
    "\n",
    "# User independent paths (repo files; set as default parameters, but anyway never hardcoded)\n",
    "cosmic_classification= f\"{work_dir}/Cosmic_Classification_v99_GRCh37.tsv\"\n",
    "\n",
    "# Other paths\n",
    "test_pdb=f\"{work_dir}/1yoh.pdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d958fc9-7d66-4fad-b288-da0b3ca7336e",
   "metadata": {},
   "source": [
    "# Class object that we utilize as framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78f13819-7199-4034-82b6-ea0f04df25bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MutationalClusterer:\n",
    "    def __init__(self, work_dir, logging=True):\n",
    "        '''\n",
    "        General File structure should be something like:\n",
    "        https://tree.nathanfriend.io/?s=(%27opGHs!(%27fancy8~fullPath!fJse~trailingSlash8~rootDot8)~K(%27K%27work_dir5C0QD64Swissprot.DB4OthA_files_for_Mlookup_in_d6.DB--IntAmediates4F_protein_mulGple_seq2.Ji4summary_staGsGcs29quJity2_df93-Results4*Mdf9*MplotsL*4*additHJ4*5Pymol_output-Example4screenshotL35PDBsQ4D6_parsA_s7%204NeighbFhood_clustAA.py43-3-%27)~vAsiH!%271%27)*%20%20-5*0HsAvaGH2_Jignment3...%2F4-*5%5Cn*6atabase7cripts8!true9.csv4AerFourGtiHonJalKsFce!L.png4Mc0_Q-S7-%01QMLKJHGFA987654320-*\n",
    "        .\n",
    "        └── work_dir/\n",
    "            ├── Conservation/\n",
    "            │   ├── Scripts\n",
    "            │   ├── Database/\n",
    "            │   │   ├── Swissprot.DB\n",
    "            │   │   └── Other_files_for_conservation_lookup_in_database.DB\n",
    "            │   ├── Intermediates/\n",
    "            │   │   ├── our_protein_multiple_seq_alignment.ali\n",
    "            │   │   ├── summary_statistics_alignment.csv\n",
    "            │   │   ├── quality_alignment_df.csv\n",
    "            │   │   └── .../\n",
    "            │   └── Results/\n",
    "            │       ├── conservation_df.csv\n",
    "            │       ├── conservation_plots.png\n",
    "            │       └── additonal\n",
    "            ├── Pymol_output/\n",
    "            │   └── Example/\n",
    "            │       ├── screenshot.png\n",
    "            │       └── .../\n",
    "            └── PDBs/\n",
    "                ├── Scripts/\n",
    "                │   ├── Database_parser_scripts \n",
    "                │   ├── Neighbourhood_clusterer.py\n",
    "                │   └── .../\n",
    "                └── .../\n",
    "        \n",
    "        '''\n",
    "        self.work_dir = work_dir #the directory we want to work in\n",
    "        self.log_dir = logging # we want to store log results for whatever we do.\n",
    "        self.gene_name = None\n",
    "        #Your other features of the class that we need.\n",
    "        \n",
    "        \n",
    "\n",
    "    def _visualize_clusters_pymol(self, pdb:str) -> None:\n",
    "        \"\"\"\n",
    "        Utility function to visualize cluster in pymol.\n",
    "        \"\"\"\n",
    "        \n",
    "        #from pymol import cmd\n",
    "        pass\n",
    "\n",
    "    def _plot_clusters(self, pdb:str) -> object:\n",
    "        \"\"\"\n",
    "        Helper function to plot some statistics or quick interactive plots to investigate clustering.\n",
    "        Mostly thought about pyplot or plotly interactive plots i.e alignment where we can see the conservation etc.\n",
    "        https://plotly.com/python/alignment-chart/\n",
    "        \"\"\"\n",
    "\n",
    "    def compute_neighbours(self, pdb:str, cutoff=8.0) -> pd.DataFrame:\n",
    "\n",
    "        parser= PDBParser()\n",
    "        # Initialize parser and retrieve structure\n",
    "        structure = parser.get_structure(\"default\", pdb)\n",
    "        atom_list = Selection.unfold_entities(structure, \"A\")  # Retrieve all atoms\n",
    "    \n",
    "        # Initialize NeighborSearch with all atoms and prepare to store results\n",
    "        ns = NeighborSearch(atom_list)\n",
    "        neighbour_dict = defaultdict(set)  # Use set to avoid duplicates\n",
    "    \n",
    "        # Define list of standard amino acids to exclude solvents and ligands\n",
    "        aa_lst = [\n",
    "            \"VAL\", \"ALA\", \"GLY\", \"TRP\", \"ARG\", \"LYS\", \"LEU\", \"ILE\", \"ASP\", \"ASN\",\n",
    "            \"GLN\", \"GLU\", \"PRO\", \"TYR\", \"PHE\", \"SER\", \"THR\", \"CYS\", \"MET\", \"HIS\"\n",
    "        ]\n",
    "    \n",
    "        # Search for neighboring residues for each atom\n",
    "        for atom in atom_list:\n",
    "            residue = atom.get_parent()\n",
    "            res_name = residue.get_resname()\n",
    "            res_id = residue.get_id()[1]\n",
    "    \n",
    "            # Skip non-amino acid residues\n",
    "            if res_name not in aa_lst:\n",
    "                continue\n",
    "    \n",
    "            # Search for neighboring residues within the cutoff distance\n",
    "            for neighbour in ns.search(atom.get_coord(), cutoff, \"R\"):\n",
    "                neighbour_id = neighbour.get_id()[1]\n",
    "                if neighbour_id != res_id:  # Exclude the residue itself\n",
    "                    neighbour_dict[res_name + str(res_id)].add(neighbour_id)\n",
    "    \n",
    "            \n",
    "        # Convert the neighbor dictionary to a list of tuples\n",
    "        neighbour_data = [(res_id, ' '.join(map(str, sorted(neighbours)))) for res_id, neighbours in neighbour_dict.items()]\n",
    "\n",
    "        # Create a pandas DataFrame\n",
    "        df_neighbours = pd.DataFrame(neighbour_data, columns=['Residue_ID', 'Neighbours'])\n",
    "        return df_neighbours\n",
    "    \n",
    "\n",
    "    def conservation(self, uniprot_id):\n",
    "        '''Gets 3 different types of Conservation:\n",
    "        - Shannon conservation: \n",
    "        Shannon entropy. \n",
    "        Higher values indicate lower conservation and greater variability at the site.\n",
    "        \n",
    "        - Relative conservation:\n",
    "        Kullback-Leibler divergence.\n",
    "        Higher values indicate greater conservation and lower variability at the site.\n",
    "        \n",
    "        - Lockless conservation\n",
    "        Evolutionary conservation parameter defined by Lockless and Ranganathan (1999). \n",
    "        Higher values indicate greater conservation and lower variability at the site.\n",
    "        '''\n",
    "\n",
    "        if self.log_dir and not os.path.exists(self.log_dir):\n",
    "            os.makedirs(self.log_dir)\n",
    "        \n",
    "        mmseq_fasta_result = self._mmseq_multi_fasta(uniprot_id=uniprot_id, outdir=self.work_dir)\n",
    "        #get 3 different conservation scores in a pandas df.\n",
    "        conserv_df = self._get_conservation(path_to_msa=mmseq_fasta_result)\n",
    "        self.conservation_df = conserv_df\n",
    "\n",
    "        conserv_df.to_csv(f\"{self.log_dir}/conservation_df.csv\")\n",
    "\n",
    "    def _get_gene_name(self, uniprot_id:str):\n",
    "    \n",
    "        fields = \"id\"\n",
    "        \n",
    "        URL = f\"https://rest.uniprot.org/uniprotkb/search?format=tsv&fields={fields}&query={uniprot_id}\"\n",
    "        resp = self._get_url(URL)\n",
    "        resp = resp.text\n",
    "        resp = resp.split(\"\\n\")\n",
    "        return resp[1]\n",
    "        \n",
    "    def _mmseq_multi_fasta(self, uniprot_id:str, outdir:str, \n",
    "                      sensitivity=7, filter_msa=0,\n",
    "                     query_id = 0.6):\n",
    "        \"\"\"\n",
    "        uniprot_id: The unique uniprot identifier used to fetch the corresponding fasta file that will be used as a template for mmseq2\n",
    "        outdir: location where result files will be stored.\n",
    "        sensitivity: mmseq2 specific parameter that goes from 1-7. The higher the more sensitive the search.\n",
    "        filter_msa = 0 default. if 1 hits are stricter.\n",
    "        query_id = 0.6 [0, 1]  the higher the more identity with query is retrieved. 1 means ONLY the query hits while 0 means take everything possible.\n",
    "        \"\"\"\n",
    "\n",
    "        #we blast with this fasta as query.\n",
    "        trgt_fasta_seq = self._get_gene_fasta(uniprot_id)\n",
    "        #Make outdir for all required files.\n",
    "        #we need to write it out to file.\n",
    "        with open(f\"{self.work_dir}/{uniprot_id}_fasta.fa\", \"w\") as fasta_out:\n",
    "            fasta_out.write(f\">{uniprot_id}\\n\")\n",
    "            fasta_out.write(trgt_fasta_seq)\n",
    "\n",
    "        #fetch pre downloaded database from a parent folder.\n",
    "        msa_file = None\n",
    "        new_location = None\n",
    "        try:\n",
    "            DB_storage_location = f\"{work_dir}\"\n",
    "            #shutil.copy(previous_path, savepath)\n",
    "            bash_curl_cmd = f\"mmseqs createdb {self.work_dir}/{uniprot_id}_fasta.fa {DB_storage_location}/query_fastaDB\" \n",
    "            bash_curl_cmd_rdy = bash_curl_cmd.split()\n",
    "            #run first cmd which setups query database based on our input fasta file\n",
    "            result_setup_query_db = run(bash_curl_cmd_rdy, stdout=PIPE, stderr=PIPE, \n",
    "                                 universal_newlines=True)\n",
    "            bash_curl_cmd_2 = f\"mmseqs search {DB_storage_location}/query_fastaDB {DB_storage_location}/swiss_DB {DB_storage_location}/result_DB {DB_storage_location}/tmp -s {sensitivity}\"    \n",
    "            bash_curl_cmd_rdy_2 = bash_curl_cmd_2.split()\n",
    "            #run 2nd cmd which blasts against swiss_DB and generates the resultDB (i.e our hits that were found)\n",
    "            result_setup_blast_db = run(bash_curl_cmd_rdy_2, stdout=PIPE, stderr=PIPE, \n",
    "                                 universal_newlines=True)\n",
    "            #mmseqs convert2fasta DB_clu_rep DB_clu_rep.fasta\n",
    "            bash_curl_cmd_5 = f\"mmseqs result2msa {DB_storage_location}/query_fastaDB {DB_storage_location}/swiss_DB {DB_storage_location}/result_DB {DB_storage_location}/{uniprot_id}_out.fasta --msa-format-mode 3 --filter-msa {filter_msa} --qid {query_id}\" \n",
    "            bash_curl_cmd_5_rdy = bash_curl_cmd_5.split()\n",
    "            result_setup_msa_convert = run(bash_curl_cmd_5_rdy, stdout=PIPE, stderr=PIPE, \n",
    "                                 universal_newlines=True)\n",
    "            #delete last line.. required.\n",
    "            sed_cmd = f'sed -e 1,4d -e $d {DB_storage_location}/{uniprot_id}_out.fasta'        \n",
    "            bash_curl_cmd_6_rdy = sed_cmd.split()\n",
    "            #f\"{DB_storage_location}/{uniprot_id}_new_out.fasta\"\n",
    "            with open(f\"{DB_storage_location}/{uniprot_id}_new_out.fasta\", \"w\") as new_fasta:\n",
    "                result_truncation = run(bash_curl_cmd_6_rdy, stdout=new_fasta, stderr=PIPE, \n",
    "                                 universal_newlines=True)\n",
    "            # Specify the path to your MSA file\n",
    "            msa_file = f\"{DB_storage_location}/{uniprot_id}_new_out.fasta\"\n",
    "            #transfer the meta file to another location and delete useless files.\n",
    "            # we need to delete : all uniprot* files. \n",
    "            # all query*. All result* \n",
    "            new_location = f\"{self.work_dir}/{uniprot_id}.fasta\"\n",
    "            shutil.copy(msa_file, new_location)\n",
    "            #remove_files_and_dirs_msa(DB_storage_location, uniprot_id=uniprot_id)\n",
    "            \n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "        #we want the path to msa_file for downstream analysis.\n",
    "        return new_location\n",
    "\n",
    "    def _get_gene_fasta(self, uniprot_id:str):\n",
    "        '''\n",
    "        Helper function to grab the sequence \n",
    "        based on the Uniprot ID\n",
    "        '''\n",
    "        fields = \"sequence\"\n",
    "        URL = f\"https://rest.uniprot.org/uniprotkb/search?format=fasta&fields={fields}&query={uniprot_id}\"\n",
    "        resp = self._get_url(URL)\n",
    "        resp = resp.iter_lines(decode_unicode=True)\n",
    "        seq = \"\"\n",
    "        i = 0\n",
    "        for lines in resp:\n",
    "            if i > 0:\n",
    "                seq += lines\n",
    "            i += 1\n",
    "        return seq\n",
    "\n",
    "    def _get_conservation(self, path_to_msa:str):    \n",
    "        '''\n",
    "        Helper function to compute 3 different types of conservation.\n",
    "        \n",
    "        - Shannon conservation: \n",
    "        Shannon entropy. \n",
    "        Higher values indicate lower conservation and greater variability at the site.\n",
    "        \n",
    "        - Relative conservation:\n",
    "        Kullback-Leibler divergence.\n",
    "        Higher values indicate greater conservation and lower variability at the site.\n",
    "        \n",
    "        - Lockless conservation\n",
    "        Evolutionary conservation parameter defined by Lockless and Ranganathan (1999). \n",
    "        Higher values indicate greater conservation and lower variability at the site.\n",
    "        '''\n",
    "        canal = Canal(fastafile=path_to_msa, #Multiple sequence alignment (MSA) of homologous sequences\n",
    "          ref=0, #Position of reference sequence in MSA, use first sequence always\n",
    "          startcount=0, # ALways 0 because our seqs are always from 1 - end\n",
    "          verbose=False) # no verbosity \n",
    "    \n",
    "        result_cons = canal.analysis(method=\"all\")\n",
    "        return result_cons\n",
    "\n",
    "    def _get_url(self, url):\n",
    "        '''Helper function that uses requests for Downloads.'''\n",
    "        try:\n",
    "            response = requests.get(url)  \n",
    "            if not response.ok:\n",
    "                print(response.text)\n",
    "        except:\n",
    "            response.raise_for_status()\n",
    "            #sys.exit() \n",
    "        return response\n",
    "\n",
    "    def _get_cosmic_mutations(self, \n",
    "                              path_to_genome_screen_tsv:str, \n",
    "                              path_to_classification_tsv:str=cosmic_classification, \n",
    "                              uniprot_id:str=None, gene_name:str=None, \n",
    "                              **kwargs)->pd.DataFrame:\n",
    "\n",
    "        path=path_to_genome_screen_tsv             \n",
    "\n",
    "        #since get_gene_names gives strange gene names sometimes (e.g. EGFR_HUMAN instead of EGFR), we allow to also directly specify gene name\n",
    "        #gene name is anyway stored it in self.gene_name so we dont need to update it for other databases\n",
    "        if gene_name is not None:\n",
    "            self.gene_name = gene_name\n",
    "        elif uniprot_id is not None:\n",
    "            self.gene_name = self._get_gene_name(uniprot_id)\n",
    "        else:\n",
    "            raise ValueError(\"Either uniprot_id or gene_name must be provided\")\n",
    "\n",
    "            \n",
    "        #default columns we want to retrieve. can be changed / added through kwargs later\n",
    "        usecols=['GENE_SYMBOL',\n",
    "         'MUTATION_AA', 'MUTATION_DESCRIPTION',\n",
    "       'MUTATION_ZYGOSITY', 'LOH', 'CHROMOSOME', \n",
    "                 'GENOME_START', 'GENOME_STOP', 'COSMIC_PHENOTYPE_ID']\n",
    "\n",
    "        df = dd.read_csv(path, sep=\"\\t\", dtype={'CHROMOSOME': 'object',\n",
    "       'MUTATION_ZYGOSITY': 'object', 'GENOME_START': 'float64',\n",
    "       'GENOME_STOP': 'float64',\n",
    "       'LOH': 'object'}, usecols=usecols)  #specify dtype / usecols to minimize memory usage required through load in.\n",
    "\n",
    "\n",
    "        #we need to switch these tuples and then map the 1letter aa code to 3letter aa \n",
    "        #for later compatibility.\n",
    "        lst =  [('Val',\"V\"), ('Ile',\"I\"), ('Leu',\"L\"), ('Glu',\"E\"), ('Gln',\"Q\"),\n",
    "                    ('Asp',\"D\"), ('Asn',\"N\"), ('His',\"H\"), ('Trp',\"W\"), ('Phe',\"F\"), ('Tyr',\"Y\"), \n",
    "                    ('Arg',\"R\"), ('Lys',\"K\"), ('Ser',\"S\"), ('Thr',\"T\"), ('Met',\"M\"), ('Ala',\"A\"), \n",
    "                    ('Gly',\"G\"), ('Pro',\"P\"), ('Cys',\"C\")]\n",
    "        \n",
    "        lst = [(y, x) for x, y in lst] #switch y and x position for convinience\n",
    "\n",
    "        canonical_aas = defaultdict(lambda: \"X\", lst) #default if key not found = \"X\"\n",
    "\n",
    "        #filtering based on \"missense\" mutation. this can be tricky and sometimes messy but lets stick with that\n",
    "        df_re = df[df[\"MUTATION_DESCRIPTION\"].str.contains(\"missense\")]\n",
    "\n",
    "        #now lets filter our uniprot gene name\n",
    "        df_re = df_re[df_re[\"GENE_SYMBOL\"] == f\"{self.gene_name}\"]\n",
    "\n",
    "        #retrieve relevant information\n",
    "        meta = ('Gene name', 'str') \n",
    "        df_re['CHROMOSOME'] = df_re['CHROMOSOME'].astype('object')\n",
    "        df_re['WT_AA'] = df_re['MUTATION_AA'].str[2].apply(lambda x: canonical_aas[x], meta=meta)\n",
    "        df_re['MUTATION_POSITION'] = df_re['MUTATION_AA'].str[3:-1]\n",
    "        df_re['MUTATED_AA'] = df_re['MUTATION_AA'].str[-1].apply(lambda x: canonical_aas[x], meta=meta)\n",
    "\n",
    "        #redundant so we drop it\n",
    "        df_re = df_re.drop(\"MUTATION_AA\", axis=1)\n",
    "\n",
    "        #now we use compute() which finally does the computation (before all actions were \"lazy\" computations\n",
    "        # so we dont actually need the RAM. now we do it though.)\n",
    "        cosmic_df = df_re.compute()\n",
    "    \n",
    "        cosmic_df[\"GENOME_START\"] = cosmic_df[\"GENOME_START\"].astype(int)\n",
    "        cosmic_df[\"GENOME_STOP\"] = cosmic_df[\"GENOME_STOP\"].astype(int)\n",
    "\n",
    "\n",
    "        #Primary site is not directly retrievable\n",
    "        #Fetch primary site from classification file based on cosmic_phenotype_id and merge\n",
    "        classification_df = pd.read_csv(path_to_classification_tsv, sep='\\t')\n",
    "        cosmic_df = pd.merge(cosmic_df, classification_df[['COSMIC_PHENOTYPE_ID', 'PRIMARY_SITE']], on='COSMIC_PHENOTYPE_ID', how='left')\n",
    "        cosmic_df = cosmic_df.drop('COSMIC_PHENOTYPE_ID', axis=1)\n",
    "        \n",
    "        #return df\n",
    "        return cosmic_df\n",
    "\n",
    "\n",
    "    def _get_gnomad_mutations(self, gene_name:str, gnomad_data_table_path:str, **kwargs)-> pd.DataFrame:\n",
    "        \"\"\"Documentation.\n",
    "        Currently this part does not convert the result to a df.\n",
    "        I will implement it and return a pandas DF\n",
    "        \"\"\"\n",
    "        mt = hl.read_matrix_table(path)  #matrix table because df would not work with such large data.\n",
    "\n",
    "\n",
    "        #string based search because there is NO API for gnomAD.\n",
    "        substring1 = Gene_name\n",
    "        substring2 = \"missense\"\n",
    "        \n",
    "        mt = mt.annotate_rows(Gene_names=mt.info.vep.map(\n",
    "            lambda x: x.split(\"\\|\")[3]) ,\n",
    "                          type_of_change = mt.info.vep.map(\n",
    "            lambda x: x.split(\"\\|\")[1]) , \n",
    "                          AA_change = mt.info.vep.map(\n",
    "            lambda x: x.split(\"\\|\")[11]) , \n",
    "                          ENST_identifier= mt.info.vep.map(\n",
    "            lambda x: x.split(\"\\|\")[6])\n",
    "    \n",
    "        ) \n",
    "                 \n",
    "        filtered_mt_2 = mt.filter_rows(\n",
    "        #hl.any(lambda x: hl.str(x).contains(substring3), mt.AA_change)\n",
    "        hl.any(lambda x: hl.str(x).contains(substring1), mt.info.vep) &\n",
    "        hl.any(lambda x: hl.str(x).contains(substring2), mt.info.vep)\n",
    "        \n",
    "        )\n",
    "                         \n",
    "        filtered_mt_3 = filtered_mt_2.annotate_rows(\n",
    "            Allele_count_int = filtered_mt_2.info.AC,\n",
    "            Allele_frequency_float = filtered_mt_2.info.AF,\n",
    "            Allele_number_int = filtered_mt_2.info.AN,\n",
    "            Gene_name_str = _replace_empty(filtered_mt_2.Gene_names), \n",
    "            Mutation_change_str = _replace_empty(filtered_mt_2.AA_change),\n",
    "            Type_of_change_str = _replace_empty(filtered_mt_2.type_of_change))\n",
    "        \n",
    "        #this can be again regulated later trough kwargs**\n",
    "        rows_to_keep = [\"Gene_name_str\", \"Mutation_change_str\", \"Type_of_change_str\", \"Allele_count_int\",\n",
    "                    \"Allele_frequency_float\", \"Allele_number_int\"]\n",
    "    \n",
    "    \n",
    "        selected_rows = filtered_mt_3.select_rows(\n",
    "            Allele_count_int=filtered_mt_3.Allele_count_int,\n",
    "            Allele_frequency_float=filtered_mt_3.Allele_frequency_float,\n",
    "            Allele_number_int=filtered_mt_3.Allele_number_int,\n",
    "            Gene_name_str=hl.str(filtered_mt_3.Gene_name_str),\n",
    "            Mutation_change_str=hl.str(filtered_mt_3.Mutation_change_str),\n",
    "            Type_of_change_str=hl.str(filtered_mt_3.Type_of_change_str)\n",
    "                )\n",
    "    \n",
    "        save_buffer = selected_rows.select_rows(*rows_to_keep)\n",
    "        select_rows_out = save_buffer.rows()\n",
    "\n",
    "        #part missing to convert to pandas DF.\n",
    "        \n",
    "        #return pd.DataFrame() \n",
    "\n",
    "    def _map_clinvar(self, gene_name:str, clinvar_variant_summary_txt:str, **kwargs)-> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Documentation missing.\n",
    "        \"\"\"\n",
    "\n",
    "        #can be regulated through kwargs\n",
    "        use_cols = [\"Type\", \"Name\", \"GeneSymbol\",\n",
    "           \"ClinicalSignificance\", \"PhenotypeList\",\n",
    "           \"Assembly\", \"ChromosomeAccession\", \n",
    "           \"Chromosome\", \"Start\", \"Stop\"]\n",
    "        \n",
    "        #this here as well / mapping needed to save memory at load in.\n",
    "        column_data_types = {\n",
    "        \"Type\": str,\n",
    "        \"Name\": str,\n",
    "        \"GeneSymbol\": str,\n",
    "        \"ClinicalSignificance\": str,\n",
    "        \"PhenotypeList\": str,\n",
    "        \"Assembly\": str,\n",
    "        \"ChromosomeAccession\": str,\n",
    "        \"Chromosome\": str,\n",
    "        \"Start\": int,\n",
    "        \"Stop\": int\n",
    "        }\n",
    "\n",
    "        #lets read in the clinvar all var file.\n",
    "        df_work = pd.read_csv(clinvar_variant_summary_txt, sep=\"\\t\", usecols=use_cols, dtype=column_data_types)\n",
    "    \n",
    "        df_work.loc[:, \"AA_change\"] = df_work[\"Name\"].str.split().str.get(-1)\n",
    "        df_work.loc[:, \"AA_change\"] = df_work[\"AA_change\"].str.replace(\"(\", \"\")\n",
    "        df_work.loc[:, \"AA_change\"] = df_work[\"AA_change\"].str.replace(\")\", \"\")\n",
    "        \n",
    "        df_work.loc[:,\"Original_AA\"] = df_work[\"AA_change\"].str[2:5]\n",
    "        df_work.loc[:,\"Modified_AA\"] = df_work[\"AA_change\"].str[-3:]\n",
    "        df_work['Position'] = pd.to_numeric(df_work['AA_change'].str[5:-3], errors='coerce')\n",
    "        \n",
    "        # Drop rows with NaN values in the 'Position' column\n",
    "        df_work.dropna(subset=['Position'], inplace=True)\n",
    "        df_work['Position'] = df_work['Position'].astype(int)\n",
    "        \n",
    "        df_work[\"Genomic_location\"] = df_work[\"Chromosome\"] + \":\" + df_work[\"Start\"].astype(str)\n",
    "        df_work[\"gnomad_aa_change\"] = \"p.\" + df_work[\"Original_AA\"] + df_work[\"Position\"].astype(str) + df_work[\"Modified_AA\"]\n",
    "        \n",
    "        df_work = df_work.drop(\"AA_change\", axis=1)\n",
    "        df_work = df_work.drop(\"Name\", axis=1)\n",
    "        df_work = df_work.drop(\"Chromosome\", axis=1)\n",
    "        df_work = df_work.drop(\"Start\", axis=1)\n",
    "        df_work = df_work.drop(\"Stop\", axis=1)\n",
    "        \n",
    "        df_work[\"Allele_count\"] = [np.nan] * len(df_work)\n",
    "        df_work[\"Allele_number\"] = [np.nan] * len(df_work)\n",
    "        df_work[\"Allele_frequency\"] = [np.nan] * len(df_work)\n",
    "        \n",
    "        \n",
    "        accepted_residues = [\"Ala\", \"Gly\", \"Ser\", \"Leu\", \"Pro\",\n",
    "                        \"Ile\", \"Val\", \"Phe\", \"Tyr\", \"Trp\",\n",
    "                         \"His\", \"Thr\", \"Asn\", \"Gln\", \"Asp\", \n",
    "                         \"Glu\",\"Cys\", \"Met\", \"Lys\", \"Arg\"]\n",
    "        \n",
    "        #filtering based on our Gene name.\n",
    "        df_clinvar = df_work[(df_work[\"Type\"] == \"single nucleotide variant\") & \n",
    "            (df_work[\"GeneSymbol\"] == Gene_name) &\n",
    "            (df_work[\"Assembly\"] == \"GRCh37\") & \n",
    "            (df_work['Original_AA'].isin(accepted_residues)) &\n",
    "            (df_work['Modified_AA'].isin(accepted_residues)) ]\n",
    "        \n",
    "        return df_clinvar\n",
    "\n",
    "\n",
    "mmcluster = MutationalClusterer(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e4bb835-2b01-4aaa-a529-7d9cd69bce17",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mmcluster' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmmcluster\u001b[49m\u001b[38;5;241m.\u001b[39mcompute_neighbours(test_pdb)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mmcluster' is not defined"
     ]
    }
   ],
   "source": [
    "mmcluster.compute_neighbours(test_pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98673213-bf6f-406b-bcdb-6b7e4a2c25a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENE_SYMBOL</th>\n",
       "      <th>MUTATION_DESCRIPTION</th>\n",
       "      <th>MUTATION_ZYGOSITY</th>\n",
       "      <th>LOH</th>\n",
       "      <th>CHROMOSOME</th>\n",
       "      <th>GENOME_START</th>\n",
       "      <th>GENOME_STOP</th>\n",
       "      <th>WT_AA</th>\n",
       "      <th>MUTATION_POSITION</th>\n",
       "      <th>MUTATED_AA</th>\n",
       "      <th>PRIMARY_SITE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>missense_variant</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7</td>\n",
       "      <td>55224477</td>\n",
       "      <td>55224477</td>\n",
       "      <td>Leu</td>\n",
       "      <td>387</td>\n",
       "      <td>Met</td>\n",
       "      <td>lung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>missense_variant</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7</td>\n",
       "      <td>55259515</td>\n",
       "      <td>55259515</td>\n",
       "      <td>Leu</td>\n",
       "      <td>805</td>\n",
       "      <td>Arg</td>\n",
       "      <td>lung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>missense_variant</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7</td>\n",
       "      <td>55259515</td>\n",
       "      <td>55259515</td>\n",
       "      <td>Leu</td>\n",
       "      <td>805</td>\n",
       "      <td>Arg</td>\n",
       "      <td>lung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>missense_variant</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7</td>\n",
       "      <td>55259515</td>\n",
       "      <td>55259515</td>\n",
       "      <td>Leu</td>\n",
       "      <td>805</td>\n",
       "      <td>Arg</td>\n",
       "      <td>lung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>missense_variant</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7</td>\n",
       "      <td>55259515</td>\n",
       "      <td>55259515</td>\n",
       "      <td>Leu</td>\n",
       "      <td>805</td>\n",
       "      <td>Arg</td>\n",
       "      <td>lung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>missense_variant</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7</td>\n",
       "      <td>55210075</td>\n",
       "      <td>55210075</td>\n",
       "      <td>Leu</td>\n",
       "      <td>62</td>\n",
       "      <td>Arg</td>\n",
       "      <td>central_nervous_system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4810</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>missense_variant</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7</td>\n",
       "      <td>55210075</td>\n",
       "      <td>55210075</td>\n",
       "      <td>Leu</td>\n",
       "      <td>62</td>\n",
       "      <td>Arg</td>\n",
       "      <td>central_nervous_system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>missense_variant</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7</td>\n",
       "      <td>55210075</td>\n",
       "      <td>55210075</td>\n",
       "      <td>Leu</td>\n",
       "      <td>62</td>\n",
       "      <td>Arg</td>\n",
       "      <td>central_nervous_system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4812</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>missense_variant</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7</td>\n",
       "      <td>55224477</td>\n",
       "      <td>55224477</td>\n",
       "      <td>Leu</td>\n",
       "      <td>387</td>\n",
       "      <td>Val</td>\n",
       "      <td>breast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>missense_variant</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7</td>\n",
       "      <td>55219001</td>\n",
       "      <td>55219001</td>\n",
       "      <td>Pro</td>\n",
       "      <td>192</td>\n",
       "      <td>Ser</td>\n",
       "      <td>skin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4814 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GENE_SYMBOL MUTATION_DESCRIPTION MUTATION_ZYGOSITY   LOH CHROMOSOME  \\\n",
       "0           EGFR     missense_variant              <NA>  <NA>          7   \n",
       "1           EGFR     missense_variant              <NA>  <NA>          7   \n",
       "2           EGFR     missense_variant              <NA>  <NA>          7   \n",
       "3           EGFR     missense_variant              <NA>  <NA>          7   \n",
       "4           EGFR     missense_variant              <NA>  <NA>          7   \n",
       "...          ...                  ...               ...   ...        ...   \n",
       "4809        EGFR     missense_variant              <NA>  <NA>          7   \n",
       "4810        EGFR     missense_variant              <NA>  <NA>          7   \n",
       "4811        EGFR     missense_variant              <NA>  <NA>          7   \n",
       "4812        EGFR     missense_variant              <NA>  <NA>          7   \n",
       "4813        EGFR     missense_variant              <NA>  <NA>          7   \n",
       "\n",
       "      GENOME_START  GENOME_STOP WT_AA MUTATION_POSITION MUTATED_AA  \\\n",
       "0         55224477     55224477   Leu               387        Met   \n",
       "1         55259515     55259515   Leu               805        Arg   \n",
       "2         55259515     55259515   Leu               805        Arg   \n",
       "3         55259515     55259515   Leu               805        Arg   \n",
       "4         55259515     55259515   Leu               805        Arg   \n",
       "...            ...          ...   ...               ...        ...   \n",
       "4809      55210075     55210075   Leu                62        Arg   \n",
       "4810      55210075     55210075   Leu                62        Arg   \n",
       "4811      55210075     55210075   Leu                62        Arg   \n",
       "4812      55224477     55224477   Leu               387        Val   \n",
       "4813      55219001     55219001   Pro               192        Ser   \n",
       "\n",
       "                PRIMARY_SITE  \n",
       "0                       lung  \n",
       "1                       lung  \n",
       "2                       lung  \n",
       "3                       lung  \n",
       "4                       lung  \n",
       "...                      ...  \n",
       "4809  central_nervous_system  \n",
       "4810  central_nervous_system  \n",
       "4811  central_nervous_system  \n",
       "4812                  breast  \n",
       "4813                    skin  \n",
       "\n",
       "[4814 rows x 11 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmcluster._get_cosmic_mutations(path_to_genome_screen_tsv=cosmic_tar, gene_name=\"EGFR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d6c2eda-38fa-4a04-ac41-012fa51baf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'get_cosmic_mutations' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_DataFrame_to_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(error)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#we save it in the folder for the protein outside of monomer / pos at the base level. \u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43msave_DataFrame_to_csv\u001b[49m(cosmic_df, path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosmic_mutations\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Step 2: Map gnomad mutations\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_DataFrame_to_csv' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize variables to avoid errors\n",
    "updated_clinvar_df = cbioport_df = cosmic_df = gnomad_df = clinvar_df = gnomad_mut_dict = gnomad_mutation_dict = None\n",
    "\n",
    "    \n",
    "# Step 1: Cosmic mutations\n",
    "try:\n",
    "    cosmic_df = get_cosmic_mutations(gene_name=main_prot_name)\n",
    "except Exception as error:\n",
    "    print(error)\n",
    "#we save it in the folder for the protein outside of monomer / pos at the base level. \n",
    "save_DataFrame_to_csv(cosmic_df, path, \"cosmic_mutations\")\n",
    "# Step 2: Map gnomad mutations\n",
    "try:\n",
    "    gnomad_table_path = map_gnomad(Gene_name=main_prot_name, outpath=oligo_state_to_check)\n",
    "    gnomad_df, gnomad_mutation_dict = gnomad_to_pandas(Gene_name=main_prot_name, path_to_tsv=gnomad_table_path, fasta_seq=main_prot_seq)\n",
    "except Exception as error:\n",
    "    print(error)\n",
    "\n",
    "save_DataFrame_to_csv(gnomad_df, path, \"gnomad_mutations\")\n",
    "# Step 3: Gather mutations from clinvar\n",
    "try:\n",
    "    clinvar_df = map_clinvar(Gene_name=main_prot_name)\n",
    "    clinvar_map_outpath = f\"{path}/clinvar_intermediate.csv\"\n",
    "except Exception as error:\n",
    "    print(error)\n",
    "\n",
    "save_DataFrame_to_csv(clinvar_df, path, \"clinvar_intermediate\")\n",
    "# Step 4: Map clinvar to gnomad\n",
    "try:\n",
    "    list_to_be_searched, clinvar_df = map_clinvar_to_gnomad_1(Gene_name=main_prot_name, clinvar_df=clinvar_df,\n",
    "                                                              gnomad_mut_dict=gnomad_mutation_dict, clinvar_mapped_df_path=clinvar_map_outpath)\n",
    "except Exception as error:\n",
    "    print(error)\n",
    "    # Update clinvar muts that were found 1 step before.\n",
    "    try:\n",
    "        updated_clinvar_df = update_clinvar_muts_based_on_gnomad(clinvar_df=clinvar_df, gnomad_dict=gnomad_mutation_dict)\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "\n",
    "save_DataFrame_to_csv(updated_clinvar_df, path, \"clinvar_mutations\")\n",
    "# Step 5: Fetch additional info from cbioportal\n",
    "try:\n",
    "    gene_name = get_hugo_name(uniprot_id)\n",
    "    print(f\"This is gene name in hugo: {gene_name}\")\n",
    "    cbioport_df = get_cbioportal_info(gene_name=gene_name)\n",
    "    save_DataFrame_to_csv(cbioport_df, path, \"cbioport_mutations\")\n",
    "except Exception as error:\n",
    "    print(error)\n",
    "\n",
    "# Print shapes (if available)\n",
    "DataFrames = [cosmic_df, updated_clinvar_df, gnomad_df, cbioport_df]\n",
    "for df in DataFrames:\n",
    "    try:\n",
    "        print(f\"This is df shape: {df.shape}\")\n",
    "    except Exception as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a926ab-942c-449b-abc9-fbf3c5399fef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
