{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d76882f-629a-47ec-9fca-3e42eff41150",
   "metadata": {},
   "source": [
    "### List of Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91b45735-f5e8-4081-a9c8-60a0729c7ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d958fc9-7d66-4fad-b288-da0b3ca7336e",
   "metadata": {},
   "source": [
    "# Class object that we utilize as framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f13819-7199-4034-82b6-ea0f04df25bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MutationalClusterer:\n",
    "    def __init__(self, work_dir, logging=True):\n",
    "        '''\n",
    "        General File structure should be something like:\n",
    "        https://tree.nathanfriend.io/?s=(%27opGHs!(%27fancy8~fullPath!fJse~trailingSlash8~rootDot8)~K(%27K%27work_dir5C0QD64Swissprot.DB4OthA_files_for_Mlookup_in_d6.DB--IntAmediates4F_protein_mulGple_seq2.Ji4summary_staGsGcs29quJity2_df93-Results4*Mdf9*MplotsL*4*additHJ4*5Pymol_output-Example4screenshotL35PDBsQ4D6_parsA_s7%204NeighbFhood_clustAA.py43-3-%27)~vAsiH!%271%27)*%20%20-5*0HsAvaGH2_Jignment3...%2F4-*5%5Cn*6atabase7cripts8!true9.csv4AerFourGtiHonJalKsFce!L.png4Mc0_Q-S7-%01QMLKJHGFA987654320-*\n",
    "        .\n",
    "        └── work_dir/\n",
    "            ├── Conservation/\n",
    "            │   ├── Scripts\n",
    "            │   ├── Database/\n",
    "            │   │   ├── Swissprot.DB\n",
    "            │   │   └── Other_files_for_conservation_lookup_in_database.DB\n",
    "            │   ├── Intermediates/\n",
    "            │   │   ├── our_protein_multiple_seq_alignment.ali\n",
    "            │   │   ├── summary_statistics_alignment.csv\n",
    "            │   │   ├── quality_alignment_df.csv\n",
    "            │   │   └── .../\n",
    "            │   └── Results/\n",
    "            │       ├── conservation_df.csv\n",
    "            │       ├── conservation_plots.png\n",
    "            │       └── additonal\n",
    "            ├── Pymol_output/\n",
    "            │   └── Example/\n",
    "            │       ├── screenshot.png\n",
    "            │       └── .../\n",
    "            └── PDBs/\n",
    "                ├── Scripts/\n",
    "                │   ├── Database_parser_scripts \n",
    "                │   ├── Neighbourhood_clusterer.py\n",
    "                │   └── .../\n",
    "                └── .../\n",
    "        \n",
    "        '''\n",
    "        self.work_dir = work_dir #the directory we want to work in\n",
    "        self.log_dir = logging # we want to store log results for whatever we do.\n",
    "        #Your other features of the class that we need.\n",
    "        \n",
    "        \n",
    "\n",
    "    def _visualize_clusters_pymol(self, pdb:str) -> None:\n",
    "        \"\"\"\n",
    "        Utility function to visualize cluster in pymol.\n",
    "        \"\"\"\n",
    "        \n",
    "        #from pymol import cmd\n",
    "        pass\n",
    "\n",
    "    def _plot_clusters(self, pdb:str) -> object:\n",
    "        \"\"\"\n",
    "        Helper function to plot some statistics or quick interactive plots to investigate clustering.\n",
    "        Mostly thought about pyplot or plotly interactive plots i.e alignment where we can see the conservation etc.\n",
    "        https://plotly.com/python/alignment-chart/\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def _compute_neighbours(self, pdb:str) -> pd.DataFrame:\n",
    "        pass\n",
    "\n",
    "    \n",
    "\n",
    "    def conservation(self, uniprot_id):\n",
    "        '''Gets 3 different types of Conservation:\n",
    "        - Shannon conservation: \n",
    "        Shannon entropy. \n",
    "        Higher values indicate lower conservation and greater variability at the site.\n",
    "        \n",
    "        - Relative conservation:\n",
    "        Kullback-Leibler divergence.\n",
    "        Higher values indicate greater conservation and lower variability at the site.\n",
    "        \n",
    "        - Lockless conservation\n",
    "        Evolutionary conservation parameter defined by Lockless and Ranganathan (1999). \n",
    "        Higher values indicate greater conservation and lower variability at the site.\n",
    "        '''\n",
    "\n",
    "        if self.log_dir and not os.path.exists(self.log_dir):\n",
    "            os.makedirs(self.log_dir)\n",
    "        \n",
    "        mmseq_fasta_result = self._mmseq_multi_fasta(uniprot_id=uniprot_id, outdir=self.work_dir)\n",
    "        #get 3 different conservation scores in a pandas df.\n",
    "        conserv_df = self._get_conservation(path_to_msa=mmseq_fasta_result)\n",
    "        self.conservation_df = conserv_df\n",
    "\n",
    "        conserv_df.to_csv(f\"{self.log_dir}/conservation_df.csv\")\n",
    "        \n",
    "    def _mmseq_multi_fasta(self, uniprot_id:str, outdir:str, \n",
    "                      sensitivity=7, filter_msa=0,\n",
    "                     query_id = 0.6):\n",
    "        \"\"\"\n",
    "        uniprot_id: The unique uniprot identifier used to fetch the corresponding fasta file that will be used as a template for mmseq2\n",
    "        outdir: location where result files will be stored.\n",
    "        sensitivity: mmseq2 specific parameter that goes from 1-7. The higher the more sensitive the search.\n",
    "        filter_msa = 0 default. if 1 hits are stricter.\n",
    "        query_id = 0.6 [0, 1]  the higher the more identity with query is retrieved. 1 means ONLY the query hits while 0 means take everything possible.\n",
    "        \"\"\"\n",
    "\n",
    "        #we blast with this fasta as query.\n",
    "        trgt_fasta_seq = self._get_gene_fasta(uniprot_id)\n",
    "        #Make outdir for all required files.\n",
    "        #we need to write it out to file.\n",
    "        with open(f\"{self.work_dir}/{uniprot_id}_fasta.fa\", \"w\") as fasta_out:\n",
    "            fasta_out.write(f\">{uniprot_id}\\n\")\n",
    "            fasta_out.write(trgt_fasta_seq)\n",
    "\n",
    "        #fetch pre downloaded database from a parent folder.\n",
    "        msa_file = None\n",
    "        new_location = None\n",
    "        try:\n",
    "            DB_storage_location = f\"{work_dir}\"\n",
    "            #shutil.copy(previous_path, savepath)\n",
    "            bash_curl_cmd = f\"mmseqs createdb {self.work_dir}/{uniprot_id}_fasta.fa {DB_storage_location}/query_fastaDB\" \n",
    "            bash_curl_cmd_rdy = bash_curl_cmd.split()\n",
    "            #run first cmd which setups query database based on our input fasta file\n",
    "            result_setup_query_db = run(bash_curl_cmd_rdy, stdout=PIPE, stderr=PIPE, \n",
    "                                 universal_newlines=True)\n",
    "            bash_curl_cmd_2 = f\"mmseqs search {DB_storage_location}/query_fastaDB {DB_storage_location}/swiss_DB {DB_storage_location}/result_DB {DB_storage_location}/tmp -s {sensitivity}\"    \n",
    "            bash_curl_cmd_rdy_2 = bash_curl_cmd_2.split()\n",
    "            #run 2nd cmd which blasts against swiss_DB and generates the resultDB (i.e our hits that were found)\n",
    "            result_setup_blast_db = run(bash_curl_cmd_rdy_2, stdout=PIPE, stderr=PIPE, \n",
    "                                 universal_newlines=True)\n",
    "            #mmseqs convert2fasta DB_clu_rep DB_clu_rep.fasta\n",
    "            bash_curl_cmd_5 = f\"mmseqs result2msa {DB_storage_location}/query_fastaDB {DB_storage_location}/swiss_DB {DB_storage_location}/result_DB {DB_storage_location}/{uniprot_id}_out.fasta --msa-format-mode 3 --filter-msa {filter_msa} --qid {query_id}\" \n",
    "            bash_curl_cmd_5_rdy = bash_curl_cmd_5.split()\n",
    "            result_setup_msa_convert = run(bash_curl_cmd_5_rdy, stdout=PIPE, stderr=PIPE, \n",
    "                                 universal_newlines=True)\n",
    "            #delete last line.. required.\n",
    "            sed_cmd = f'sed -e 1,4d -e $d {DB_storage_location}/{uniprot_id}_out.fasta'        \n",
    "            bash_curl_cmd_6_rdy = sed_cmd.split()\n",
    "            #f\"{DB_storage_location}/{uniprot_id}_new_out.fasta\"\n",
    "            with open(f\"{DB_storage_location}/{uniprot_id}_new_out.fasta\", \"w\") as new_fasta:\n",
    "                result_truncation = run(bash_curl_cmd_6_rdy, stdout=new_fasta, stderr=PIPE, \n",
    "                                 universal_newlines=True)\n",
    "            # Specify the path to your MSA file\n",
    "            msa_file = f\"{DB_storage_location}/{uniprot_id}_new_out.fasta\"\n",
    "            #transfer the meta file to another location and delete useless files.\n",
    "            # we need to delete : all uniprot* files. \n",
    "            # all query*. All result* \n",
    "            new_location = f\"{self.work_dir}/{uniprot_id}.fasta\"\n",
    "            shutil.copy(msa_file, new_location)\n",
    "            #remove_files_and_dirs_msa(DB_storage_location, uniprot_id=uniprot_id)\n",
    "            \n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "        #we want the path to msa_file for downstream analysis.\n",
    "        return new_location\n",
    "\n",
    "    def _get_gene_fasta(self, uniprot_id:str):\n",
    "        '''\n",
    "        Helper function to grab the sequence \n",
    "        based on the Uniprot ID\n",
    "        '''\n",
    "        fields = \"sequence\"\n",
    "        URL = f\"https://rest.uniprot.org/uniprotkb/search?format=fasta&fields={fields}&query={uniprot_id}\"\n",
    "        resp = self._get_url(URL)\n",
    "        resp = resp.iter_lines(decode_unicode=True)\n",
    "        seq = \"\"\n",
    "        i = 0\n",
    "        for lines in resp:\n",
    "            if i > 0:\n",
    "                seq += lines\n",
    "            i += 1\n",
    "        return seq\n",
    "\n",
    "    def _get_conservation(self, path_to_msa:str):    \n",
    "        '''\n",
    "        Helper function to compute 3 different types of conservation.\n",
    "        \n",
    "        - Shannon conservation: \n",
    "        Shannon entropy. \n",
    "        Higher values indicate lower conservation and greater variability at the site.\n",
    "        \n",
    "        - Relative conservation:\n",
    "        Kullback-Leibler divergence.\n",
    "        Higher values indicate greater conservation and lower variability at the site.\n",
    "        \n",
    "        - Lockless conservation\n",
    "        Evolutionary conservation parameter defined by Lockless and Ranganathan (1999). \n",
    "        Higher values indicate greater conservation and lower variability at the site.\n",
    "        '''\n",
    "        canal = Canal(fastafile=path_to_msa, #Multiple sequence alignment (MSA) of homologous sequences\n",
    "          ref=0, #Position of reference sequence in MSA, use first sequence always\n",
    "          startcount=0, # ALways 0 because our seqs are always from 1 - end\n",
    "          verbose=False) # no verbosity \n",
    "    \n",
    "        result_cons = canal.analysis(method=\"all\")\n",
    "        return result_cons\n",
    "\n",
    "    def _get_url(self, url):\n",
    "        '''Helper function that uses requests for Downloads.'''\n",
    "        try:\n",
    "            response = requests.get(url)  \n",
    "            if not response.ok:\n",
    "                print(response.text)\n",
    "        except:\n",
    "            response.raise_for_status()\n",
    "            #sys.exit() \n",
    "        return response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
